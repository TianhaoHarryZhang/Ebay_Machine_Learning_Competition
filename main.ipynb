{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4120e66524aa4a2382c984cb34f1bbb6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1970016028fe4bb28f3d2044a5d12199","IPY_MODEL_c4ac58d7907d474d872cee629f562255","IPY_MODEL_3b4dd82797ec4a12ae7e6729b0be039c"],"layout":"IPY_MODEL_be9af3832beb4a74bda38c08a241a152"}},"1970016028fe4bb28f3d2044a5d12199":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c6f7f0ee7484d2ca2ec771764af1df4","placeholder":"​","style":"IPY_MODEL_eee13f0f397240a68807373f0b453fa4","value":"Map: 100%"}},"c4ac58d7907d474d872cee629f562255":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7588bd28331446c0bd30ddd613fa18d3","max":4000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_898cf2dd87e14b49b80028eb151c114c","value":4000}},"3b4dd82797ec4a12ae7e6729b0be039c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5600f3a07a3d4d4f9b64cc1cfb74d2f7","placeholder":"​","style":"IPY_MODEL_9e122ac9c2bd4682b8a35f21533b2e79","value":" 4000/4000 [00:01&lt;00:00, 3894.24 examples/s]"}},"be9af3832beb4a74bda38c08a241a152":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c6f7f0ee7484d2ca2ec771764af1df4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee13f0f397240a68807373f0b453fa4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7588bd28331446c0bd30ddd613fa18d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"898cf2dd87e14b49b80028eb151c114c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5600f3a07a3d4d4f9b64cc1cfb74d2f7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9e122ac9c2bd4682b8a35f21533b2e79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e5e2fd5465e49499a22eb13bcd758c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4b60c04acad445a6a52ca091b8f229eb","IPY_MODEL_fb9e023fcdf4420fb4d630dfeac7817a","IPY_MODEL_09f6fa3094cd4d9bb1e6f0455e790c53"],"layout":"IPY_MODEL_875bfa8bd46b4082bf1578c2aa3b2372"}},"4b60c04acad445a6a52ca091b8f229eb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b46062f4302f4a98b1c78e027558fac8","placeholder":"​","style":"IPY_MODEL_485ff92ac534400899fefe514f1a59fc","value":"Map: 100%"}},"fb9e023fcdf4420fb4d630dfeac7817a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_391f3982edbe4f1ab15f512c78d672cb","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ec079a4f4684c938bde888896940ead","value":1000}},"09f6fa3094cd4d9bb1e6f0455e790c53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_917d7633b6564666a8933502fa215f84","placeholder":"​","style":"IPY_MODEL_d9e0373b9f1b4c818ca483c5ad6e0998","value":" 1000/1000 [00:00&lt;00:00, 1360.58 examples/s]"}},"875bfa8bd46b4082bf1578c2aa3b2372":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b46062f4302f4a98b1c78e027558fac8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"485ff92ac534400899fefe514f1a59fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"391f3982edbe4f1ab15f512c78d672cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ec079a4f4684c938bde888896940ead":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"917d7633b6564666a8933502fa215f84":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9e0373b9f1b4c818ca483c5ad6e0998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Import & Config"],"metadata":{"id":"943u4Ovh08qN"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPCOoVQ1RTrE","executionInfo":{"status":"ok","timestamp":1693161578018,"user_tz":240,"elapsed":831,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"e7759b25-a544-4a77-f722-30eb15cf64e3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install datasets transformers==4.28.0 -q\n","!pip install wandb -q\n","!pip install seqeval -q\n","!pip install evaluate -q\n","!pip install accelerate -U -q"],"metadata":{"id":"QRYxRroJ1ML4","executionInfo":{"status":"ok","timestamp":1693161606562,"user_tz":240,"elapsed":28547,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import csv\n","import re\n","import pandas as pd\n","import pickle\n","import numpy as np\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","from transformers import AutoModel, AutoModelForTokenClassification, AutoTokenizer, AutoConfig, DataCollatorForTokenClassification, Trainer, TrainingArguments, pipeline\n","from datasets import load_dataset, load_metric\n","import wandb\n","import evaluate\n","from torch.utils.data.dataloader import DataLoader\n","from tqdm import tqdm"],"metadata":{"id":"RUZpLOEL0-9e","executionInfo":{"status":"ok","timestamp":1693161625232,"user_tz":240,"elapsed":18674,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# if you want to use wandb, run these blocks\n","# wandb.login()"],"metadata":{"id":"_PqBDuj71CgL","executionInfo":{"status":"ok","timestamp":1693161625233,"user_tz":240,"elapsed":6,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(1006)"],"metadata":{"id":"uv2-8y5Q1etI","executionInfo":{"status":"ok","timestamp":1693161625233,"user_tz":240,"elapsed":5,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device\n","# if ur running it on Mac, change it to:\n","# device = 'mps' if torch.backends.mps.is_available() else 'cpu'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"d9IxpapCWbTf","executionInfo":{"status":"ok","timestamp":1693161625394,"user_tz":240,"elapsed":166,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"7d1ae702-8730-4041-d992-ec6fc5a68d96"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'cuda'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["# Prepare data"],"metadata":{"id":"1mvL64hu1_kG"}},{"cell_type":"code","source":["def data_preparation():\n","  df = pd.read_csv(\"/content/drive/MyDrive/2023-ebay-ml/data/Train_Tagged_Titles.tsv\",\n","                 sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)\n","  Text_List = []\n","  Record_Number_List = list(df[\"Record Number\"].unique())\n","\n","  for number in Record_Number_List:\n","    sentence = \"\"\n","    append = \"\"\n","    token_list = []\n","\n","    df_one_number = df[df[\"Record Number\"] == number]\n","    df_one_number.reset_index(drop=True, inplace=True)\n","\n","    i = 0\n","    while i < df_one_number.shape[0]:\n","      token = df_one_number.loc[i, \"Token\"]\n","      tag = df_one_number.loc[i, \"Tag\"]\n","\n","      if pd.isna(df_one_number.loc[i, \"Tag\"]):\n","        token_list.insert(-1, token)\n","        if i == df_one_number.shape[0]-1:\n","            sentence += f\"[{' '.join(token_list[:-1])}]({token_list[-1]}) \"\n","            token_list = []\n","        i += 1\n","        continue\n","      if token_list != []:\n","        sentence += f\"[{' '.join(token_list[:-1])}]({token_list[-1]}) \"\n","      if tag == \"No Tag\":\n","        append_ = f\"{token} \"\n","        sentence += append_\n","        i += 1\n","        token_list = []\n","        continue\n","      if i == df_one_number.shape[0] - 1:\n","        sentence += f\"[{token}]({tag}) \"\n","        break\n","\n","      token_list = [token,tag]\n","      i += 1\n","\n","    Text_List.append(sentence[:-1])  # remove additional space at the end\n","\n","  return Text_List"],"metadata":{"id":"-0p3adPl2N2i","executionInfo":{"status":"ok","timestamp":1693161625395,"user_tz":240,"elapsed":4,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/2023-ebay-ml/data/\"\n","\n","if os.path.exists(path+\"Train.pkl\") and os.path.exists(path+\"Eval.pkl\"):\n","    Raw_Train_Data = pickle.load(open(path+\"Train.pkl\", \"rb\"))\n","    Raw_Eval_Data = pickle.load(open(path+\"Eval.pkl\", \"rb\"))\n","\n","else:\n","    Prepared_data = data_preparation()\n","    #print(Prepared_data[0])\n","\n","    random.shuffle(Prepared_data)  # already set seed at the beginning\n","    test_fraction = 0.2\n","    split_index = int(len(Prepared_data) * test_fraction)\n","\n","    Raw_Eval_Data = Prepared_data[:split_index]\n","    Raw_Train_Data = Prepared_data[split_index:]\n","\n","    pickle.dump(Raw_Train_Data, open(path+\"Train.pkl\", 'wb'))\n","    pickle.dump(Raw_Eval_Data, open(path+\"Eval.pkl\", 'wb'))"],"metadata":{"id":"zHdRTv714xfI","executionInfo":{"status":"ok","timestamp":1693161625395,"user_tz":240,"elapsed":4,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Change format into NER"],"metadata":{"id":"V2phNmwf9JAF"}},{"cell_type":"code","source":["# using BIO tagging\n","def get_tokens_with_entities(raw_text: str):\n","    raw_tokens = re.split(r\"\\s(?![^\\[]*\\])\", raw_text)\n","    entity_value_pattern = r\"\\[(?P<value>.+?)\\]\\((?P<entity>.+?)\\)\"\n","    entity_value_pattern_compiled = re.compile(entity_value_pattern, flags=re.I|re.M)\n","\n","    tokens_with_entities = []\n","\n","    for raw_token in raw_tokens:\n","        match = entity_value_pattern_compiled.match(raw_token)\n","        if match:\n","            raw_entity_name, raw_entity_value = match.group(\"entity\"), match.group(\"value\") # [token](tag)\n","\n","            for i, raw_entity_token in enumerate(re.split(\"\\s\", raw_entity_value)):\n","                entity_prefix = \"B\" if i == 0 else \"I\"\n","                entity_name = f\"{entity_prefix}-{raw_entity_name}\"\n","                tokens_with_entities.append((raw_entity_token, entity_name))\n","        else:\n","            tokens_with_entities.append((raw_token, \"O\"))\n","\n","    return tokens_with_entities\n","\n","\n","# customized dataset class\n","class NERDataMaker:\n","    def __init__(self, texts):\n","        self.unique_entities = []\n","        self.processed_texts = []\n","\n","        temp_processed_texts = []\n","        for text in texts:\n","            tokens_with_entities = get_tokens_with_entities(text)\n","            for _, ent in tokens_with_entities:\n","                if ent not in self.unique_entities:\n","                    self.unique_entities.append(ent)\n","            temp_processed_texts.append(tokens_with_entities)\n","\n","        self.unique_entities.sort(key=lambda ent: ent if ent != \"O\" else \"\")\n","\n","        for tokens_with_entities in temp_processed_texts:\n","            self.processed_texts.append([(t, self.unique_entities.index(ent)) for t, ent in tokens_with_entities])\n","\n","    @property\n","    def id2label(self):\n","        return dict(enumerate(self.unique_entities))\n","\n","    @property\n","    def label2id(self):\n","        return {v:k for k, v in self.id2label.items()}\n","\n","    def __len__(self):\n","        return len(self.processed_texts)\n","\n","    def __getitem__(self, idx):\n","        def _process_tokens_for_one_text(id, tokens_with_encoded_entities):\n","            ner_tags = []\n","            tokens = []\n","            for t, ent in tokens_with_encoded_entities:\n","                ner_tags.append(ent)\n","                tokens.append(t)\n","\n","            return {\n","                \"id\": id,\n","                \"ner_tags\": ner_tags,\n","                \"tokens\": tokens\n","            }\n","\n","        tokens_with_encoded_entities = self.processed_texts[idx]\n","        if isinstance(idx, int):\n","            return _process_tokens_for_one_text(idx, tokens_with_encoded_entities)\n","        else:\n","            return [_process_tokens_for_one_text(i+idx.start, tee) for i, tee in enumerate(tokens_with_encoded_entities)]\n","\n","    def as_hf_dataset(self, tokenizer):\n","        from datasets import Dataset, Features, Value, ClassLabel, Sequence\n","        def tokenize_and_align_labels(examples):\n","            tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n","            # print(\"tokenized_inputs_1\", tokenized_inputs.keys())\n","\n","            labels = []\n","            for i, label in enumerate(examples[f\"ner_tags\"]):\n","                word_ids = tokenized_inputs.word_ids(batch_index=i)  # Map tokens to their respective word.\n","                previous_word_idx = None\n","                label_ids = []\n","                for word_idx in word_ids:  # Set the special tokens to -100.\n","                    if word_idx is None:\n","                        label_ids.append(-100)\n","                    elif word_idx != previous_word_idx:  # Only label the first token of a given word.\n","                        label_ids.append(label[word_idx])\n","                    else:\n","                        label_ids.append(-100)\n","                    previous_word_idx = word_idx\n","                labels.append(label_ids)\n","\n","            tokenized_inputs[\"labels\"] = labels\n","            # print(\"tokenized_inputs_2\", tokenized_inputs.keys())\n","            return tokenized_inputs\n","\n","        ids, ner_tags, tokens = [], [], []\n","        for i, pt in enumerate(self.processed_texts):\n","            ids.append(i)\n","            pt_tokens,pt_tags = list(zip(*pt))\n","            ner_tags.append(pt_tags)\n","            tokens.append(pt_tokens)\n","        data = {\n","            \"id\": ids,\n","            \"ner_tags\": ner_tags,\n","            \"tokens\": tokens\n","        }\n","        features = Features({\n","            \"tokens\": Sequence(Value(\"string\")),\n","            \"ner_tags\": Sequence(ClassLabel(names=self.unique_entities)),\n","            \"id\": Value(\"int32\")\n","        })\n","        ds = Dataset.from_dict(data, features)\n","        tokenized_ds = ds.map(tokenize_and_align_labels, batched=True)\n","        return tokenized_ds"],"metadata":{"id":"xAUChs4e66SZ","executionInfo":{"status":"ok","timestamp":1693161625395,"user_tz":240,"elapsed":4,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["NER_Train = NERDataMaker(Raw_Train_Data)\n","NER_Eval = NERDataMaker(Raw_Eval_Data)"],"metadata":{"id":"D_dSji4x9TA0","executionInfo":{"status":"ok","timestamp":1693161626162,"user_tz":240,"elapsed":770,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["# Training"],"metadata":{"id":"t-A1iaJX_SBK"}},{"cell_type":"code","source":["CFG = dict(\n","    model_name=\"bert-base-multilingual-uncased\", # TODO: consider pretrained model carefully\n","    output_dir=path+\"results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    seed=1006,\n","    max_length=128\n",")"],"metadata":{"id":"OWsU7YTL9a3F","executionInfo":{"status":"ok","timestamp":1693161626163,"user_tz":240,"elapsed":4,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(CFG[\"model_name\"], padding=\"max_length\", max_length=CFG[\"max_length\"])\n","data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=\"max_length\", max_length=CFG[\"max_length\"]) # enough for this competitions, or just make it another hyperparameter"],"metadata":{"id":"A55MuTEt_pYY","executionInfo":{"status":"ok","timestamp":1693161626673,"user_tz":240,"elapsed":513,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["model = AutoModelForTokenClassification.from_pretrained(CFG[\"model_name\"])"],"metadata":{"id":"T9g28D_mDAR0","executionInfo":{"status":"ok","timestamp":1693161631912,"user_tz":240,"elapsed":5242,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"cfd77de4-8d0b-4441-cbfe-ad006723dd15"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["new_classification_layer = nn.Linear(model.classifier.in_features, len(NER_Train.unique_entities))\n","model.classifier = new_classification_layer\n","model.id2label = NER_Train.id2label\n","model.label2id = NER_Train.label2id\n","model.num_labels = len(NER_Train.unique_entities)\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NRUcG93wCsPr","executionInfo":{"status":"ok","timestamp":1693161642524,"user_tz":240,"elapsed":10615,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"aecf815e-e214-4638-ccb6-69d2f7159564"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=63, bias=True)\n",")"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# expand model's vocab\n","brand_names = []\n","with open(\"/content/drive/MyDrive/2023-ebay-ml/data/names.txt\", \"r\") as f:\n","  for line in f:\n","    brand_names.append(line.strip())"],"metadata":{"id":"nhMAI0r8WkE4","executionInfo":{"status":"ok","timestamp":1693161642525,"user_tz":240,"elapsed":3,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["tokenizer.add_tokens(brand_names)\n","model.resize_token_embeddings(len(tokenizer))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nd6XNKfUZ0ss","executionInfo":{"status":"ok","timestamp":1693161644010,"user_tz":240,"elapsed":1487,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"e805377e-bc4f-457d-e15b-9c22a3d9a05a"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Embedding(109263, 768)"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["# let's see the outcome\n","tokenizer.tokenize(\"ABC design Beige Sneaker GR . 42\") # cuz we're using uncased model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkWgCYFTaFUR","executionInfo":{"status":"ok","timestamp":1693161644010,"user_tz":240,"elapsed":3,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"d2625e4b-8ff8-49f3-dd1f-91397e418315"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['abc design', 'bei', '##ge', 'sn', '##eak', '##er', 'gr', '.', '42']"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["train_ds = NER_Train.as_hf_dataset(tokenizer=tokenizer)\n","eval_ds = NER_Eval.as_hf_dataset(tokenizer=tokenizer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["4120e66524aa4a2382c984cb34f1bbb6","1970016028fe4bb28f3d2044a5d12199","c4ac58d7907d474d872cee629f562255","3b4dd82797ec4a12ae7e6729b0be039c","be9af3832beb4a74bda38c08a241a152","7c6f7f0ee7484d2ca2ec771764af1df4","eee13f0f397240a68807373f0b453fa4","7588bd28331446c0bd30ddd613fa18d3","898cf2dd87e14b49b80028eb151c114c","5600f3a07a3d4d4f9b64cc1cfb74d2f7","9e122ac9c2bd4682b8a35f21533b2e79","7e5e2fd5465e49499a22eb13bcd758c2","4b60c04acad445a6a52ca091b8f229eb","fb9e023fcdf4420fb4d630dfeac7817a","09f6fa3094cd4d9bb1e6f0455e790c53","875bfa8bd46b4082bf1578c2aa3b2372","b46062f4302f4a98b1c78e027558fac8","485ff92ac534400899fefe514f1a59fc","391f3982edbe4f1ab15f512c78d672cb","8ec079a4f4684c938bde888896940ead","917d7633b6564666a8933502fa215f84","d9e0373b9f1b4c818ca483c5ad6e0998"]},"id":"7-AYHNYi_ypm","executionInfo":{"status":"ok","timestamp":1693161646614,"user_tz":240,"elapsed":2606,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"f464a952-d15a-4e83-9e02-1d55fbcd7688"},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/4000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4120e66524aa4a2382c984cb34f1bbb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e5e2fd5465e49499a22eb13bcd758c2"}},"metadata":{}}]},{"cell_type":"code","source":["train_ds[0].keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ORFk-fEPaa0V","executionInfo":{"status":"ok","timestamp":1693161646615,"user_tz":240,"elapsed":7,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"3a75a4b2-9646-4d89-aa1a-c0da9122014a"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dict_keys(['id', 'ner_tags', 'tokens', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'])"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# remove unused columns before passing it to a dataloader, as it cannot deal with 'str'\n","train_ds = train_ds.remove_columns([\"tokens\", \"id\", \"ner_tags\"])\n","eval_ds = eval_ds.remove_columns([\"tokens\", \"id\", \"ner_tags\"])"],"metadata":{"id":"vMSD-CAmsKrK","executionInfo":{"status":"ok","timestamp":1693161646615,"user_tz":240,"elapsed":5,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(train_ds, shuffle=True, collate_fn=data_collator, batch_size=CFG[\"per_device_train_batch_size\"])\n","eval_dataloader = DataLoader(eval_ds, shuffle=True, collate_fn=data_collator, batch_size=CFG[\"per_device_eval_batch_size\"])"],"metadata":{"id":"LhCRFfY6mv_S","executionInfo":{"status":"ok","timestamp":1693161646615,"user_tz":240,"elapsed":5,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# customized training function\n","def train_fn(model, dl, optimizer):\n","  train_loss = 0\n","  for idx, batch in enumerate(tqdm(dl, total=len(dl))):\n","    input_ids = batch[\"input_ids\"].to(device, dtype=torch.long)\n","    attention_mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n","    token_type_ids = batch[\"token_type_ids\"].to(device, dtype=torch.long)\n","    labels = batch[\"labels\"].to(device, dtype=torch.long)\n","    # print(input_ids.shape)\n","    # print(attention_mask.shape)\n","    # print(labels.shape)\n","\n","    output = model(input_ids,\n","                   token_type_ids=None, # useless to this task\n","                   attention_mask=attention_mask,\n","                   labels=labels)\n","\n","    step_loss = output[0]\n","    prediction = output[1]\n","    # print(\"pred:\", prediction)\n","\n","    step_loss.sum().backward()\n","    optimizer.step()\n","    train_loss += step_loss\n","    optimizer.zero_grad()\n","\n","  return train_loss.sum()"],"metadata":{"id":"C3BVB0-ORQ4k","executionInfo":{"status":"ok","timestamp":1693161646615,"user_tz":240,"elapsed":5,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def eval_fn(model, dl):\n","    model.eval()\n","\n","    eval_loss = 0\n","    predictions = np.array([], dtype = np.int64).reshape(0, CFG[\"max_length\"]) # pad to max_len\n","    true_labels = np.array([], dtype = np.int64).reshape(0, CFG[\"max_length\"])\n","\n","    with torch.no_grad():\n","        for idx, batch in enumerate(tqdm(dl, total=len(dl))):\n","            input_ids = batch[\"input_ids\"].to(device, dtype=torch.long)\n","            attention_mask = batch[\"attention_mask\"].to(device, dtype=torch.long)\n","            labels = batch[\"labels\"].to(device, dtype=torch.long)\n","\n","            output = model(input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=attention_mask,\n","                            labels=labels)\n","\n","            step_loss = output[0]\n","            eval_prediction = output[1]\n","            # print(\"pred:\", eval_prediction)\n","\n","            eval_loss += step_loss\n","\n","            eval_prediction = np.argmax(eval_prediction.detach().to('cpu').numpy(), axis=2)\n","            # print(\"pred:\", eval_prediction)\n","            actual = labels.to('cpu').numpy()\n","            # print(\"actual:\", actual)\n","\n","            predictions = np.concatenate((predictions, eval_prediction), axis=0)\n","            true_labels = np.concatenate((true_labels, actual), axis=0)\n","\n","        return eval_loss.sum(), predictions, true_labels"],"metadata":{"id":"uAyBQGXPVb-I","executionInfo":{"status":"ok","timestamp":1693161646616,"user_tz":240,"elapsed":5,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["def train_engine(model, train_dl, eval_dl):\n","    best_f1_score = 0\n","    params = model.parameters()\n","    optimizer = torch.optim.Adam(params, lr=CFG[\"learning_rate\"])\n","\n","    for i in range(CFG[\"num_train_epochs\"]):\n","        train_loss = train_fn(model, train_dl, optimizer)\n","        eval_loss, eval_predictions, true_labels = eval_fn(model, eval_dl)\n","        # print(eval_predictions, true_labels)\n","        print(f\"Epoch {i} , Train loss: {train_loss}, Eval loss: {eval_loss}\")\n","\n","        metric = evaluate.load(\"seqeval\")  # for sequence labeling\n","        label_list = NER_Train.unique_entities\n","        true_predictions = [\n","            [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","            for prediction, label in zip(eval_predictions, true_labels)\n","        ]\n","        true_labels = [\n","            [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","            for prediction, label in zip(eval_predictions, true_labels)\n","        ]\n","        # need to change this based on the description of the competition\n","        # (it's just on the official webpage)\n","        results = metric.compute(predictions=true_predictions, references=true_labels)\n","        print(\"overall_f1:\", results['overall_f1'])\n","\n","        if results['overall_f1'] > best_f1_score:\n","            best_f1_score = results['overall_f1']\n","            print(\"Saving the model\")\n","            # torch.save(model.state_dict(), '/content/drive/MyDrive/2023-ebay-ml/data/results/'+CFG['model_name'].replace('/','-')+'.pt')\n","            model.save_pretrained('/content/drive/MyDrive/2023-ebay-ml/data/results/'+CFG['model_name'].replace('/','-')+'/')\n","            tokenizer.save_pretrained('/content/drive/MyDrive/2023-ebay-ml/data/results/'+CFG['model_name'].replace('/','-')+'/')\n","\n","    return model"],"metadata":{"id":"eC7XVzvzUC1O","executionInfo":{"status":"ok","timestamp":1693161646616,"user_tz":240,"elapsed":5,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["model = train_engine(model, train_dataloader, eval_dataloader)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NjDTl0-OZI86","outputId":"91d023af-fca8-4c36-abdc-b319e0f659ba","executionInfo":{"status":"ok","timestamp":1693162104284,"user_tz":240,"elapsed":457673,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":25,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/125 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","100%|██████████| 125/125 [01:18<00:00,  1.60it/s]\n","100%|██████████| 32/32 [00:06<00:00,  4.60it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 , Train loss: 119.5377197265625, Eval loss: 54.143558502197266\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["overall_f1: 0.6303663603172605\n","Saving the model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 125/125 [01:21<00:00,  1.53it/s]\n","100%|██████████| 32/32 [00:07<00:00,  4.49it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 , Train loss: 35.7421760559082, Eval loss: 58.441097259521484\n","overall_f1: 0.6405186801900116\n","Saving the model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 125/125 [01:21<00:00,  1.53it/s]\n","100%|██████████| 32/32 [00:07<00:00,  4.50it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2 , Train loss: 20.01285171508789, Eval loss: 63.14146423339844\n","overall_f1: 0.6393411223903467\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 125/125 [01:21<00:00,  1.53it/s]\n","100%|██████████| 32/32 [00:07<00:00,  4.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3 , Train loss: 12.857878684997559, Eval loss: 62.42898178100586\n","overall_f1: 0.6455913159398209\n","Saving the model\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 125/125 [01:21<00:00,  1.53it/s]\n","100%|██████████| 32/32 [00:07<00:00,  4.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4 , Train loss: 8.328378677368164, Eval loss: 68.25306701660156\n","overall_f1: 0.634610472541507\n"]}]},{"cell_type":"markdown","source":["# Old version"],"metadata":{"id":"7So5HQ2YXgPR"}},{"cell_type":"code","source":["# training_args = TrainingArguments(\n","#     output_dir=CFG[\"output_dir\"],\n","#     evaluation_strategy=CFG[\"evaluation_strategy\"],\n","#     learning_rate=CFG[\"learning_rate\"],\n","#     per_device_train_batch_size=CFG[\"per_device_train_batch_size\"],\n","#     per_device_eval_batch_size=CFG[\"per_device_eval_batch_size\"],\n","#     num_train_epochs=CFG[\"num_train_epochs\"],\n","#     #weight_decay=CFG[\"weight_decay\"],\n","#     seed=CFG[\"seed\"],\n","# )\n","\n","# trainer = Trainer(\n","#     model=model,\n","#     args=training_args,\n","#     train_dataset=train_ds,\n","#     eval_dataset=eval_ds,\n","#     tokenizer=tokenizer,\n","#     data_collator=data_collator,\n","#     compute_metrics=compute_metrics,\n","# )"],"metadata":{"id":"C8hGkjKIA07I","executionInfo":{"status":"ok","timestamp":1693162104284,"user_tz":240,"elapsed":16,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["# run = wandb.init(\n","#     project='ebay-ml',\n","#     config=CFG,\n","# )"],"metadata":{"id":"VGBVDR0oABwF","executionInfo":{"status":"ok","timestamp":1693162104284,"user_tz":240,"elapsed":2,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# trainer.train()"],"metadata":{"id":"XWBk2hxcE8Ly","executionInfo":{"status":"ok","timestamp":1693162104284,"user_tz":240,"elapsed":2,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# metrics=trainer.evaluate()\n","# wandb.log(metrics)\n","\n","# run.finish()"],"metadata":{"id":"vhVLvOnDIR9I","executionInfo":{"status":"ok","timestamp":1693162104285,"user_tz":240,"elapsed":3,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["# Customized Inference"],"metadata":{"id":"wRbyPYo4G8bj"}},{"cell_type":"code","source":["# read quiz data\n","path = \"/content/drive/MyDrive/2023-ebay-ml/data/\"\n","\n","if os.path.exists(path+\"Quiz.pkl\"):\n","    df_quiz = pickle.load(open(path+\"Quiz.pkl\", \"rb\"))\n","\n","else:\n","    df_all = pd.read_csv(path+\"Listing_Titles.tsv\", sep=\"\\t\", dtype=str, keep_default_na=False, na_values=[\"\"], quoting=csv.QUOTE_NONE)\n","    df_quiz = df_all[5000:30000] # that's what the competition says\n","    pickle.dump(df_quiz, open(path+\"Quiz.pkl\", 'wb'))"],"metadata":{"id":"Jd5jtFocoMIZ","executionInfo":{"status":"ok","timestamp":1693162104285,"user_tz":240,"elapsed":3,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# format: (no header, no specific ordering)\n","# Record Number, Aspect Name, Aspect Value\n","\n","def inference(df, model, tokenizer):\n","  df_result = pd.DataFrame(columns=[\"Record Number\", \"Aspect Name\", \"Aspect Value\"])\n","\n","  model.eval()\n","  with torch.no_grad():\n","    for idx, row in df.iterrows():\n","      # print(\"*****************\")\n","      id = row[\"Record Number\"]\n","      title = row[\"Title\"]\n","      title_list = title.split()\n","      # print(title_list)\n","      input_tensor = tokenizer(title, return_tensors=\"pt\").to(device)\n","      tokens = tokenizer.convert_ids_to_tokens(input_tensor[\"input_ids\"][0])\n","      logits = model(**input_tensor)[\"logits\"]\n","      preds = torch.argmax(logits, dim=2).tolist()[0]\n","\n","      entities = []\n","      current_entity = None\n","\n","      for i, (tok, pred) in enumerate(zip(tokens, preds)):\n","        label = model.id2label[pred]\n","        if tok.startswith(\"##\"):\n","          tokens[i] = tokens[i][2:]\n","          if current_entity is not None: current_entity[\"end\"] = i\n","        else:\n","          if current_entity is not None: entities.append(current_entity)\n","          current_entity = {\"start\": i, \"end\": i, \"label\": label}\n","\n","      preds_list = []\n","      for entity in entities[1:]:\n","        entity[\"text\"] = \"\".join(tokens[entity[\"start\"]:entity[\"end\"] + 1])\n","        preds_list.append(entity[\"label\"])\n","\n","      # in case the preds don't follow BIO tagging rule\n","      # can eliminate by using different model like (BERT-BiLSTM-CRF)\n","      prev = preds_list[0]\n","      if prev.startswith('I'):\n","        preds_list[0] = 'B'+prev[1:]\n","        prev = 'B'+prev[1:]\n","      for i in range(1,len(preds_list)):\n","        if preds_list[i].startswith('I') and preds_list[i][2:] != prev[2:]:\n","          preds_list[i] = 'B'+preds_list[i][1:]\n","        prev = preds_list[i]\n","      # print(preds_list)\n","\n","      # combine and output\n","      final_output = []\n","      current = {\"word\": [], \"label\": None}\n","      for word, pred in zip(title_list, preds_list):\n","        if pred == 'O': continue\n","        elif pred.startswith(\"B-\"):\n","          if current[\"word\"] == []:\n","            current['word'].append(word)\n","            current['label'] = pred[2:]\n","          else:\n","            res = pd.Series({\"Record Number\": id,\n","                              \"Aspect Name\": current['label'],\n","                              \"Aspect Value\": \" \".join(current['word'])})\n","            df_result = pd.concat([df_result, res.to_frame().T], ignore_index=True)\n","            current['word'] = [word]\n","            current['label'] = pred[2:]\n","        elif pred.startswith(\"I-\"):\n","          current['word'].append(word)\n","      if current['word'] != []:\n","        res = pd.Series({\"Record Number\": id,\n","                              \"Aspect Name\": current['label'],\n","                              \"Aspect Value\": \" \".join(current['word'])})\n","        df_result = pd.concat([df_result, res.to_frame().T], ignore_index=True)\n","\n","    return df_result"],"metadata":{"id":"oUKsCIZ9WWI3","executionInfo":{"status":"ok","timestamp":1693162104452,"user_tz":240,"elapsed":170,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["df_result = inference(df_quiz.head(5), model, tokenizer).reset_index(drop=True) # please change the ratio when submitting"],"metadata":{"id":"_eZBdD_Qw7jb","executionInfo":{"status":"ok","timestamp":1693162104452,"user_tz":240,"elapsed":2,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["df_result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"Z1Jsv2jcL0VM","executionInfo":{"status":"ok","timestamp":1693162104580,"user_tz":240,"elapsed":130,"user":{"displayName":"刘欣悦","userId":"07269853958112221817"}},"outputId":"e7d57bd8-997f-4e13-eb76-158c263aee17"},"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Record Number       Aspect Name                      Aspect Value\n","0           5001             Marke                              NIKE\n","1           5001      Produktlinie                              FREE\n","2           5001            Modell                               RUN\n","3           5001            Modell  3 SHIELD 5.0 SNEAKERS LAUFSCHUHE\n","4           5001              Stil                                GR\n","5           5001        Produktart                              . EU\n","6           5001     EU-Schuhgröße                             UK 11\n","7           5001     US-Schuhgröße                             30 CM\n","8           5002         Abteilung                             DAMEN\n","9           5002        Produktart                            SCHUHE\n","10          5002  Herstellernummer                           SNEAKER\n","11          5002              Stil                             WEISS\n","12          5002             Farbe                                38\n","13          5002     EU-Schuhgröße                               NEU\n","14          5003             Marke                          Converse\n","15          5003              Stil                          Sneakers\n","16          5003         Abteilung                             Damen\n","17          5003     EU-Schuhgröße                                36\n","18          5003      Obermaterial                             Leder\n","19          5003             Farbe                              grau\n","20          5004             Marke                            Adidas\n","21          5004        Produktart                  Freizeitschuh Gr\n","22          5004     UK-Schuhgröße                                 9\n","23          5005             Marke                           K Swiss\n","24          5005        Produktart                            Schuhe\n","25          5005             Farbe                             Leder\n","26          5005      Obermaterial                             größe\n","27          5005     EU-Schuhgröße                               low\n","28          5005   Schuhschaft-Typ                           sneaker\n","29          5005              Stil                           Newport\n","30          5005      Produktlinie                          02160002\n","31          5005  Herstellernummer                      schwarz-weiß"],"text/html":["\n","  <div id=\"df-93807156-94ce-4add-a957-61a645730485\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Record Number</th>\n","      <th>Aspect Name</th>\n","      <th>Aspect Value</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5001</td>\n","      <td>Marke</td>\n","      <td>NIKE</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>5001</td>\n","      <td>Produktlinie</td>\n","      <td>FREE</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5001</td>\n","      <td>Modell</td>\n","      <td>RUN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5001</td>\n","      <td>Modell</td>\n","      <td>3 SHIELD 5.0 SNEAKERS LAUFSCHUHE</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5001</td>\n","      <td>Stil</td>\n","      <td>GR</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5001</td>\n","      <td>Produktart</td>\n","      <td>. EU</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5001</td>\n","      <td>EU-Schuhgröße</td>\n","      <td>UK 11</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>5001</td>\n","      <td>US-Schuhgröße</td>\n","      <td>30 CM</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5002</td>\n","      <td>Abteilung</td>\n","      <td>DAMEN</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>5002</td>\n","      <td>Produktart</td>\n","      <td>SCHUHE</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>5002</td>\n","      <td>Herstellernummer</td>\n","      <td>SNEAKER</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>5002</td>\n","      <td>Stil</td>\n","      <td>WEISS</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>5002</td>\n","      <td>Farbe</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>5002</td>\n","      <td>EU-Schuhgröße</td>\n","      <td>NEU</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>5003</td>\n","      <td>Marke</td>\n","      <td>Converse</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>5003</td>\n","      <td>Stil</td>\n","      <td>Sneakers</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>5003</td>\n","      <td>Abteilung</td>\n","      <td>Damen</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>5003</td>\n","      <td>EU-Schuhgröße</td>\n","      <td>36</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>5003</td>\n","      <td>Obermaterial</td>\n","      <td>Leder</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>5003</td>\n","      <td>Farbe</td>\n","      <td>grau</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>5004</td>\n","      <td>Marke</td>\n","      <td>Adidas</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>5004</td>\n","      <td>Produktart</td>\n","      <td>Freizeitschuh Gr</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>5004</td>\n","      <td>UK-Schuhgröße</td>\n","      <td>9</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>5005</td>\n","      <td>Marke</td>\n","      <td>K Swiss</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>5005</td>\n","      <td>Produktart</td>\n","      <td>Schuhe</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>5005</td>\n","      <td>Farbe</td>\n","      <td>Leder</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>5005</td>\n","      <td>Obermaterial</td>\n","      <td>größe</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>5005</td>\n","      <td>EU-Schuhgröße</td>\n","      <td>low</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>5005</td>\n","      <td>Schuhschaft-Typ</td>\n","      <td>sneaker</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>5005</td>\n","      <td>Stil</td>\n","      <td>Newport</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>5005</td>\n","      <td>Produktlinie</td>\n","      <td>02160002</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>5005</td>\n","      <td>Herstellernummer</td>\n","      <td>schwarz-weiß</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93807156-94ce-4add-a957-61a645730485')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-93807156-94ce-4add-a957-61a645730485 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-93807156-94ce-4add-a957-61a645730485');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-4c60b838-4d58-4d57-93ab-39979476cb7d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c60b838-4d58-4d57-93ab-39979476cb7d')\"\n","            title=\"Suggest charts.\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const charts = await google.colab.kernel.invokeFunction(\n","          'suggestCharts', [key], {});\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-4c60b838-4d58-4d57-93ab-39979476cb7d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":33}]}]}